{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b5A5tEQlo_qU"
      },
      "outputs": [],
      "source": [
        "# !pip install wandb -qU\n",
        "# import wandb\n",
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG3-_ByI0xF9",
        "outputId": "0c40471f-0ba2-40f6-fd16-267573a63207"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # # Unzip data\n",
        "# !unzip /content/drive/MyDrive/generated_images_10Kids_cropped.zip -d my_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-RqFIM-o_qb",
        "outputId": "97540303-32b8-468d-8d88-7b8c2873526f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /home/steffen/.local/lib/python3.10/site-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /home/steffen/.local/lib/python3.10/site-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /home/steffen/.local/lib/python3.10/site-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: filelock in /home/steffen/.local/lib/python3.10/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: sympy in /home/steffen/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: networkx in /home/steffen/.local/lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /home/steffen/.local/lib/python3.10/site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: triton==2.3.1 in /home/steffen/.local/lib/python3.10/site-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/steffen/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
            "Requirement already satisfied: numpy in /home/steffen/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/steffen/.local/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/steffen/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/steffen/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in /home/steffen/.local/lib/python3.10/site-packages (4.66.4)\n",
            "Requirement already satisfied: torchsummary in /home/steffen/.local/lib/python3.10/site-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zXcLBaj8o_qb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ioKil3xi95PM"
      },
      "outputs": [],
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=0)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(32 * 12 * 12, 41)  # Updated to 32 * 12 * 12\n",
        "        self.fc1komma5 = nn.Linear(41,32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward_one(self, x):\n",
        "        x = F.relu(self.conv1(x)) # 8 * 112 * 112\n",
        "        x = F.max_pool2d(x, 2)  # output size: (8, 56, 56)\n",
        "        x = F.relu(self.conv2(x)) # 16* 52 * 52\n",
        "        x = F.max_pool2d(x, 2)  # output size: (16, 26, 26)\n",
        "        x = F.relu(self.conv3(x)) # 32 * 24 * 24\n",
        "        x = F.max_pool2d(x, 2)  # output size: (32, 12, 12)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc1komma5(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        output1 = self.forward_one(input1)\n",
        "        output2 = self.forward_one(input2)\n",
        "        distance = torch.abs(output1 - output2)\n",
        "        output = torch.sigmoid(self.fc3(distance))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvxdb-lgo_qc",
        "outputId": "78171c77-1c04-4e9a-c2b9-ebe6f268635f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: 128\n",
            "LR: 0.01\n",
            "Epochs: 5\n",
            "Device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/steffen/.local/lib/python3.10/site-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 112, 112]              80\n",
            "            Conv2d-2           [-1, 16, 52, 52]           3,216\n",
            "            Conv2d-3           [-1, 32, 24, 24]           4,640\n",
            "            Linear-4                   [-1, 41]         188,969\n",
            "            Linear-5                   [-1, 32]           1,344\n",
            "            Linear-6                   [-1, 16]             528\n",
            "            Conv2d-7          [-1, 8, 112, 112]              80\n",
            "            Conv2d-8           [-1, 16, 52, 52]           3,216\n",
            "            Conv2d-9           [-1, 32, 24, 24]           4,640\n",
            "           Linear-10                   [-1, 41]         188,969\n",
            "           Linear-11                   [-1, 32]           1,344\n",
            "           Linear-12                   [-1, 16]             528\n",
            "           Linear-13                    [-1, 1]              17\n",
            "================================================================\n",
            "Total params: 397,571\n",
            "Trainable params: 397,571\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 600.25\n",
            "Forward/backward pass size (MB): 2.47\n",
            "Params size (MB): 1.52\n",
            "Estimated Total Size (MB): 604.24\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/5:   0%|          | 0/20781 [00:00<?, ?batch/s]/home/steffen/.local/lib/python3.10/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n",
            "Epoch 1/5:   1%|â–         | 285/20781 [01:10<1:25:02,  4.02batch/s, loss=0.687]"
          ]
        }
      ],
      "source": [
        "class FaceDataset(Dataset):\n",
        "    def __init__(self, image_folder, people_dirs, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.people_dirs = people_dirs\n",
        "        self.transform = transform\n",
        "        self.image_pairs = []\n",
        "        self.labels = []\n",
        "        self._prepare_data()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        for person_dir in self.people_dirs:\n",
        "            person_path = os.path.join(self.image_folder, person_dir)\n",
        "            images = os.listdir(person_path)\n",
        "            for i in range(len(images)):\n",
        "                for j in range(i + 1, len(images)):\n",
        "                    self.image_pairs.append((os.path.join(person_path, images[i]), os.path.join(person_path, images[j])))\n",
        "                    self.labels.append(1)\n",
        "\n",
        "                    # Add negative samples\n",
        "                    neg_person = person_dir\n",
        "                    while neg_person == person_dir:\n",
        "                        neg_person = random.choice(self.people_dirs)\n",
        "\n",
        "                    neg_images = os.listdir(os.path.join(self.image_folder, neg_person))\n",
        "                    random_image_index = random.randrange(start=0, stop=len(neg_images))\n",
        "                    self.image_pairs.append((os.path.join(person_path, images[i]), os.path.join(self.image_folder, neg_person, neg_images[random_image_index])))\n",
        "                    self.labels.append(0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img1_path, img2_path = self.image_pairs[idx]\n",
        "        label = self.labels[idx]\n",
        "        img1 = Image.open(img1_path).convert('L')\n",
        "        img2 = Image.open(img2_path).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Function to split dataset\n",
        "def split_dataset(image_folder, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    people_dirs = os.listdir(image_folder)\n",
        "    random.shuffle(people_dirs)\n",
        "\n",
        "    train_end = int(train_ratio * len(people_dirs))\n",
        "    val_end = train_end + int(val_ratio * len(people_dirs))\n",
        "\n",
        "    train_dirs = people_dirs[:train_end]\n",
        "    val_dirs = people_dirs[train_end:val_end]\n",
        "    test_dirs = people_dirs[val_end:]\n",
        "\n",
        "    return train_dirs, val_dirs, test_dirs\n",
        "\n",
        "# Hyperparameters and setup\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f'Batch size: {batch_size}')\n",
        "print(f'LR: {learning_rate}')\n",
        "print(f'Epochs: {epochs}')\n",
        "print(f'Device: {device}')\n",
        "\n",
        "# Data augmentation and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "image_folder = 'generated_images_10Kids_cropped'  # Update with the path to your dataset\n",
        "train_dirs, val_dirs, test_dirs = split_dataset(image_folder)\n",
        "\n",
        "train_dataset = FaceDataset(image_folder, train_dirs, transform=transform)\n",
        "val_dataset = FaceDataset(image_folder, val_dirs, transform=transform)\n",
        "test_dataset = FaceDataset(image_folder, test_dirs, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Model, loss, and optimizer\n",
        "model = SiameseNetwork().to(device)\n",
        "summary(model, [(1, 112, 112), (1, 112, 112)])\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training script with validation\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
        "    accumulation_steps = 4\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\") as pbar:\n",
        "            for i,(img1, img2, label) in enumerate(train_loader):\n",
        "                img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    outputs = model(img1, img2).squeeze()\n",
        "                    loss = criterion(outputs, label)\n",
        "                    loss = loss / accumulation_steps\n",
        "                scaler.scale(loss).backward()\n",
        "                if (i+1) % accumulation_steps == 0:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                    optimizer.zero_grad()\n",
        "                running_loss += loss.item() * accumulation_steps\n",
        "                pbar.set_postfix(loss=running_loss / (pbar.n + 1))\n",
        "                pbar.update(1)\n",
        "        scheduler.step()\n",
        "        val_loss, val_accuracy = evaluate(model, val_loader, criterion)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
        "\n",
        "        # Save the model\n",
        "        torch.save(model.state_dict(), f'networks/network_epoch{epoch}.pth')\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for img1, img2, label in data_loader:\n",
        "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(img1, img2).squeeze()\n",
        "                loss = criterion(outputs, label)\n",
        "            running_loss += loss.item()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == label).sum().item()\n",
        "            total += label.size(0)\n",
        "    accuracy = correct / total\n",
        "    return running_loss / len(data_loader), accuracy\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, val_loader, criterion, optimizer, epochs=epochs)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
