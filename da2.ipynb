{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnartschik\u001b[0m (\u001b[33muni-muensterda2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 128\n",
      "LR: 0.005\n",
      "Epochs: 1\n",
      "Device: cuda\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Das System kann den angegebenen Pfad nicht finden: 'start_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 148\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# image_folder = 'generated_images_10Kids_cropped'  # Update with the path to your dataset\u001b[39;00m\n\u001b[0;32m    147\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update with the path to your dataset\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mFaceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Model, loss, and optimizer\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m, in \u001b[0;36mFaceDataset.__init__\u001b[1;34m(self, image_folder, transform)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_pairs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 41\u001b[0m, in \u001b[0;36mFaceDataset._prepare_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 41\u001b[0m     people_dirs \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m person_dir \u001b[38;5;129;01min\u001b[39;00m people_dirs:\n\u001b[0;32m     43\u001b[0m         person_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_folder, person_dir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Das System kann den angegebenen Pfad nicht finden: 'start_dataset'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"DA2 CS.ipynb\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1UqaEm83WuUD6yCIQzsy8iAIU5U37yIpv\n",
    "\"\"\"\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Unzip data\n",
    "# !unzip /content/drive/MyDrive/generated_images_10Kids_cropped.zip -d my_data\n",
    "\n",
    "# !pip install wandb -qU\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_pairs = []\n",
    "        self.labels = []\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        people_dirs = os.listdir(self.image_folder)\n",
    "        for person_dir in people_dirs:\n",
    "            person_path = os.path.join(self.image_folder, person_dir)\n",
    "            images = os.listdir(person_path)\n",
    "            for i in range(len(images)):\n",
    "                for j in range(i + 1, len(images)):\n",
    "                    self.image_pairs.append((os.path.join(person_path, images[i]), os.path.join(person_path, images[j])))\n",
    "                    self.labels.append(1)\n",
    "                    \n",
    "                    # Add negative samples\n",
    "                    neg_person = person_dir\n",
    "                    while neg_person == person_dir:\n",
    "                        neg_person = people_dirs[torch.randint(len(people_dirs), (1,)).item()]\n",
    "                        \n",
    "                    neg_images = os.listdir(os.path.join(self.image_folder, neg_person))\n",
    "                    self.image_pairs.append((os.path.join(person_path, images[i]), os.path.join(self.image_folder, neg_person, neg_images[0])))\n",
    "                    self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_path, img2_path = self.image_pairs[idx]\n",
    "        label = self.labels[idx]\n",
    "        img1 = Image.open(img1_path).convert('L')\n",
    "        img2 = Image.open(img2_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Siamese Network\n",
    "class TinySiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinySiameseNetwork, self).__init__()\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, kernel_size=3, stride=1, padding=1), # double to (1,4...)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(2, 4, kernel_size=3, stride=1, padding=1), # double to (4,8...)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4*28*28, 8), # double to (8*28*28, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1), # double to (16,1)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.conv_net(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        output1 = self.forward_once(img1)\n",
    "        output2 = self.forward_once(img2)\n",
    "        return torch.abs(output1 - output2)\n",
    "\n",
    "# Training script\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # Using tqdm to display the progress bar\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "            for img1, img2, label in train_loader:\n",
    "                img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(img1, img2).squeeze()  # Squeeze the output to match the label shape\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                pbar.set_postfix(loss=running_loss / (pbar.n + 1))\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), f'networks/network_epoch{epoch}.pth')\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Hyperparameters and setup\n",
    "batch_size = 128\n",
    "learning_rate = 0.005\n",
    "epochs = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'Batch size: {batch_size}')\n",
    "print(f'LR: {learning_rate}')\n",
    "print(f'Epochs: {epochs}')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "# image_folder = 'generated_images_10Kids_cropped'  # Update with the path to your dataset\n",
    "\n",
    "image_folder = 'start_dataset'  # Update with the path to your dataset\n",
    "dataset = FaceDataset(image_folder, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "model = TinySiameseNetwork().to(device)\n",
    "\n",
    "summary(model, [(1, 112, 112), (1, 112, 112)])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, criterion, optimizer, epochs=epochs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
